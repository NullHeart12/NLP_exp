# NLP_exp
## Hfut Natural Language Processing (NLP) Experiments / 合肥工业大学自然语言处理实验
### Exp1: Collection and Organization of Corpus
This experiment involves counting the frequency of n-grams. We were provided with corpora of Chinese Song Ci and People's Daily for processing. In processing the Song Ci corpus, I handled it by individual characters. However, upon completion, I realized that it could be more effectively processed using a Python library named 'jiayan', which is designed for tokenizing ancient Chinese texts.

### Exp2: Sentence Generation Using Exp1 Corpus
This experiment focuses on generating sentences using the results from Exp1. I employed a top-k algorithm for sentence generation to introduce more randomness into the sequence.

### Exp3: Sentence Tokenization Using Exp1 Corpus
In this experiment, sentences provided by users are tokenized using the results from Exp1.

### About the Project
Project 1 comprises Exp1. Exp2 and Exp3 are part of Project 2. In Project 1, I compile it into .lib file for Project 2. In Project 2, I implemented frontend-backend separation technology with Qt6. The backend exclusively utilizes the C++ STL library, making it versatile for integration with different frontends. Additionally, I developed a setup project for deploying the solution on the Windows platform.

### About the GUI
![image](https://github.com/NullHeart12/NLP_exp/assets/125792130/9f6a53dd-213d-424e-ae1f-a9afa17aab04)
